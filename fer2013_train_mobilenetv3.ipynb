{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc93ef51",
   "metadata": {},
   "source": [
    "\n",
    "# 표정 기반 피로도(전처 단계) — FER2013 감정 분류 가중치 학습 노트북\n",
    "\n",
    "이 노트북은 **FER2013** 감정 분류 모델을 빠르게 학습해 **가중치(.pth)** 파일을 저장합니다.  \n",
    "추후 피로도 스코어링(Valence–Arousal, EAR/MAR 결합 등)의 **전처 기반(감정 확률)** 으로 바로 사용할 수 있습니다.\n",
    "\n",
    "> **요약**\n",
    "> - 데이터: FER2013 (Kaggle `msambare/fer2013`) — *자동 다운로드(선택)*\n",
    "> - 모델: MobileNetV3-Small (pretrained)\n",
    "> - 손실: CrossEntropy\n",
    "> - 전략: Stratified Train/Val split, AMP, Cosine LR, Early Stopping\n",
    "> - 결과: `weights/fer_mobilenetv3_small_best.pth` + `class_to_idx.json`\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "824ded56",
   "metadata": {},
   "source": [
    "\n",
    "## 0. 준비 사항\n",
    "- (선택) Kaggle API 사용시: `~/.kaggle/kaggle.json` 배치 필요\n",
    "- 또는 `data/fer2013/` 폴더에 **ImageFolder 구조**(`train/class_x/*.jpg`, `test/class_x/*.jpg`)로 미리 데이터 배치\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e51e0752",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: 3.12.3 | packaged by conda-forge | (main, Apr 15 2024, 18:20:11) [MSC v.1938 64 bit (AMD64)]\n",
      "Torch : 2.7.1+cu126\n",
      "CUDA  : True 1\n",
      "Torchvision: 0.22.1+cu126\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# 환경 체크\n",
    "import sys, torch, torchvision\n",
    "print(\"Python:\", sys.version)\n",
    "print(\"Torch :\", torch.__version__)\n",
    "print(\"CUDA  :\", torch.cuda.is_available(), torch.cuda.device_count())\n",
    "print(\"Torchvision:\", torchvision.__version__)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e231c8",
   "metadata": {},
   "source": [
    "\n",
    "## 1. (선택) Kaggle에서 FER2013 다운로드\n",
    "- Kaggle 토큰이 있으면 자동으로 `msambare/fer2013`를 내려받아 `data/fer2013`에 전개합니다.\n",
    "- 토큰이 없으면 **이 셀을 건너뛰고**, 이미 준비된 `data/fer2013`을 사용하세요.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e1efe11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kaggle token detected. Downloading FER2013...\n",
      "Unzipped to data/fer2013\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os, zipfile, shutil, subprocess, sys\n",
    "\n",
    "DATA_DIR = \"data/fer2013\"\n",
    "os.makedirs(\"data\", exist_ok=True)\n",
    "\n",
    "def has_kaggle_token():\n",
    "    home = os.path.expanduser(\"~\")\n",
    "    return os.path.exists(os.path.join(home, \".kaggle\", \"kaggle.json\"))\n",
    "\n",
    "if has_kaggle_token() and not os.path.exists(DATA_DIR):\n",
    "    print(\"Kaggle token detected. Downloading FER2013...\")\n",
    "    try:\n",
    "        # install kaggle cli if missing\n",
    "        try:\n",
    "            import kaggle  # noqa\n",
    "        except Exception:\n",
    "            subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"kaggle\"])\n",
    "        # download\n",
    "        subprocess.check_call([\"kaggle\", \"datasets\", \"download\", \"-d\", \"msambare/fer2013\", \"-p\", \"data\"])\n",
    "        # unzip\n",
    "        zip_path = \"data/fer2013.zip\"\n",
    "        with zipfile.ZipFile(zip_path, \"r\") as zf:\n",
    "            zf.extractall(\"data\")\n",
    "        # dataset unzips to data/fer2013\n",
    "        print(\"Unzipped to data/fer2013\")\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(\"Kaggle download failed:\", e)\n",
    "else:\n",
    "    if os.path.exists(DATA_DIR):\n",
    "        print(\"Using existing data at:\", DATA_DIR)\n",
    "    else:\n",
    "        print(\"No Kaggle token and no data/fer2013 folder found.\")\n",
    "        print(\"Please prepare FER2013 in ImageFolder format under data/fer2013.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42c2b16c",
   "metadata": {},
   "source": [
    "\n",
    "## 2. 데이터 구조 확인 & 클래스 라벨 정리\n",
    "- FER2013 Kaggle 버전의 경우 `data/fer2013/train` & `data/fer2013/test`에 클래스별 폴더가 있습니다.\n",
    "- 여기서는 **train**에서 stratified split으로 **val**을 생성합니다.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e05ce22e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exists: True True\n",
      "Classes: ['angry', 'disgust', 'fear', 'happy', 'neutral', 'sad', 'surprise']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "from glob import glob\n",
    "\n",
    "root = \"data\"\n",
    "train_root = os.path.join(root, \"train\")\n",
    "test_root  = os.path.join(root, \"test\")\n",
    "\n",
    "print(\"Exists:\", os.path.exists(train_root), os.path.exists(test_root))\n",
    "if os.path.exists(train_root):\n",
    "    classes = sorted([d for d in os.listdir(train_root) if os.path.isdir(os.path.join(train_root, d))])\n",
    "    print(\"Classes:\", classes)\n",
    "else:\n",
    "    classes = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "445dc439-2dbb-4fac-accb-50bd187aeb69",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 사람들의 감정 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "99e8aa46-9f7e-4074-871f-50ae3b667504",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/2wBDAQgJCQwLDBgNDRgyIRwhMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjL/wAARCAAwADADASIAAhEBAxEB/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/8QAHwEAAwEBAQEBAQEBAQAAAAAAAAECAwQFBgcICQoL/8QAtREAAgECBAQDBAcFBAQAAQJ3AAECAxEEBSExBhJBUQdhcRMiMoEIFEKRobHBCSMzUvAVYnLRChYkNOEl8RcYGRomJygpKjU2Nzg5OkNERUZHSElKU1RVVldYWVpjZGVmZ2hpanN0dXZ3eHl6goOEhYaHiImKkpOUlZaXmJmaoqOkpaanqKmqsrO0tba3uLm6wsPExcbHyMnK0tPU1dbX2Nna4uPk5ebn6Onq8vP09fb3+Pn6/9oADAMBAAIRAxEAPwDmNOkvdWvXlMvBHIPb3rX0eHbrMUiwPNblTvIJ5rE8MXJkhDK3LLhvpXRXmrXUEaQ2cy26gfPKFyQPRRQB6bZaV5emx/ZZfM2xhTGfvL/jXAXe5dcdTnIJGCMGksdaubW3t7q0n1Oe5ZiAZmBiYYOeOq/XpXUaklv4htrXUrKNvtpIEsTqEbGOeT1wenegCrpxO8n2rA1iR5tct0zwCTXTWsEkDSJKjRuByrDBFc5Iol8Rgf3VoA8w8CX4S4lglOcj5Qa9LtWtnILxbveuMfS9Oea3vIJCki4JKDaT6qR2rftb9wRyMelAHfaUmmMFKwBWHXnrWPrV1q9jdTLZWUPkt8yXM7fKi98Y71W07UAkyux4z69aTWbJ9cufMfUZhaqRtgiAB9+aAN7wxfDXdAjWK7F3dWoYTDGH+Y54BJJUf41jQQFvEUxxyBiqn2a7E8dnp0ElhdQhpYbsu244AyM+4/DNdRqniaWwuNCh/wCXa6RnnP8AGWABGfQnk0AeOXuq3eoPEkdqIIo8ljv3FjjAqmdUkhOHBHNTW+oQBTkOc/7NRXktrOpwrA/7tAAPEzR8bvxq7Y+LbwTAQLvLHpXNPHEH+63/AHzXSeHbGxuba5Zbqa3uYUzlYgxOTgY54x1JoA6u28R3Fze2FtcX4imEgkddwAjQdck+o4x71LqU+lpA9wrv9qilE1uYicb9wOW9RjP51UGleHIogyXGpCTqzBV+Y+pzk0+K00G4QiWTUlI6FXH9aAP/2Q==",
      "image/png": "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",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=48x48>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir = 'data/train'\n",
    "dataset = datasets.ImageFolder(data_dir)\n",
    "dataset.__getitem__(1)[0]\n",
    "dataset.__getitem__(3)[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a1850fb",
   "metadata": {},
   "source": [
    "\n",
    "## 3. 데이터셋/데이터로더 구성\n",
    "- Augmentations: RandomResizedCrop, RandomHorizontalFlip, ColorJitter(약하게), RandomGrayscale(약하게)\n",
    "- 입력 크기: 224×224 (MobileNetV3 권장)\n",
    "- Stratified Split: train → train/val (기본 90:10)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a6185ab4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved class_to_idx: {'angry': 0, 'disgust': 1, 'fear': 2, 'happy': 3, 'neutral': 4, 'sad': 5, 'surprise': 6}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(25838, 2871, 7178)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from torchvision import datasets, transforms\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "import numpy as np, json, os\n",
    "\n",
    "IMG_SIZE = 224\n",
    "BATCH_SIZE = 128\n",
    "VAL_RATIO = 0.1\n",
    "NUM_WORKERS = 4\n",
    "\n",
    "train_tfms = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(IMG_SIZE, scale=(0.8, 1.0)),\n",
    "    transforms.RandomHorizontalFlip(0.5),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "    transforms.RandomGrayscale(p=0.1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "val_tfms = transforms.Compose([\n",
    "    transforms.Resize(IMG_SIZE+32),\n",
    "    transforms.CenterCrop(IMG_SIZE),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "train_dataset_full = datasets.ImageFolder(train_root, transform=train_tfms)\n",
    "y_full = np.array([label for _, label in train_dataset_full.samples])\n",
    "\n",
    "sss = StratifiedShuffleSplit(n_splits=1, test_size=VAL_RATIO, random_state=42)\n",
    "train_idx, val_idx = next(sss.split(np.zeros_like(y_full), y_full))\n",
    "\n",
    "train_dataset = Subset(train_dataset_full, train_idx)\n",
    "# validation은 augmentation 없이 고정 transform 사용\n",
    "val_dataset_full = datasets.ImageFolder(train_root, transform=val_tfms)\n",
    "val_dataset = Subset(val_dataset_full, val_idx)\n",
    "\n",
    "test_dataset = datasets.ImageFolder(test_root, transform=val_tfms) if os.path.exists(test_root) else None\n",
    "\n",
    "class_to_idx = train_dataset_full.class_to_idx\n",
    "os.makedirs(\"weights\", exist_ok=True)\n",
    "with open(\"weights/class_to_idx.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(class_to_idx, f, ensure_ascii=False, indent=2)\n",
    "print(\"Saved class_to_idx:\", class_to_idx)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS, pin_memory=True)\n",
    "val_loader   = DataLoader(val_dataset,   batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, pin_memory=True)\n",
    "test_loader  = DataLoader(test_dataset,  batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, pin_memory=True) if test_dataset else None\n",
    "\n",
    "len(train_dataset), len(val_dataset), (len(test_dataset) if test_dataset else None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f38ec5da-4505-48dd-a83a-4a61e6de6d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = next(iter(test_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1441a29c",
   "metadata": {},
   "source": [
    "\n",
    "## 4. 모델 정의 (MobileNetV3-Small, pretrained)\n",
    "- 출력 차원 = 클래스 수\n",
    "- Optim: AdamW\n",
    "- Scheduler: CosineAnnealingLR\n",
    "- AMP(autocast + GradScaler) 사용\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f2ff18e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/mobilenet_v3_small-047dcff4.pth\" to C:\\Users\\hamseungjun/.cache\\torch\\hub\\checkpoints\\mobilenet_v3_small-047dcff4.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 9.83M/9.83M [00:00<00:00, 97.8MB/s]\n",
      "C:\\Users\\hamseungjun\\AppData\\Local\\Temp\\ipykernel_31292\\1309777606.py:19: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler(enabled=(device.type==\"cuda\"))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision.models import mobilenet_v3_small, MobileNet_V3_Small_Weights\n",
    "\n",
    "num_classes = len(class_to_idx) if class_to_idx else 7  # FER2013 일반적으로 7클래스\n",
    "weights = MobileNet_V3_Small_Weights.DEFAULT\n",
    "model = mobilenet_v3_small(weights=weights)\n",
    "model.classifier[3] = nn.Linear(model.classifier[3].in_features, num_classes)\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "epochs = 30\n",
    "\n",
    "# 총 스텝 기반이 아니므로 간단히 CosineAnnealingLR 사용\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs, eta_min=1e-5)\n",
    "\n",
    "scaler = torch.cuda.amp.GradScaler(enabled=(device.type==\"cuda\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05053899",
   "metadata": {},
   "source": [
    "\n",
    "## 5. 학습 루프 (조기 종료 + F1 계산)\n",
    "- EarlyStopping: 검증 F1이 `patience` 동안 개선 없으면 종료\n",
    "- 지표: Accuracy, Macro-F1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d975c83f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hamseungjun\\AppData\\Local\\Temp\\ipykernel_31292\\2481922711.py:36: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(device.type==\"cuda\")):\n",
      "C:\\Users\\hamseungjun\\AppData\\Local\\Temp\\ipykernel_31292\\2481922711.py:12: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(device.type==\"cuda\")):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01/30] loss=1.2231  val_acc=0.5670  val_f1=0.4457  time=75.4s\n",
      "  ↳ Best improved. Saved to weights/fer_mobilenetv3_small_best.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hamseungjun\\AppData\\Local\\Temp\\ipykernel_31292\\2481922711.py:36: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(device.type==\"cuda\")):\n",
      "C:\\Users\\hamseungjun\\AppData\\Local\\Temp\\ipykernel_31292\\2481922711.py:12: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(device.type==\"cuda\")):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02/30] loss=0.9914  val_acc=0.6102  val_f1=0.5436  time=41.6s\n",
      "  ↳ Best improved. Saved to weights/fer_mobilenetv3_small_best.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hamseungjun\\AppData\\Local\\Temp\\ipykernel_31292\\2481922711.py:36: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(device.type==\"cuda\")):\n",
      "C:\\Users\\hamseungjun\\AppData\\Local\\Temp\\ipykernel_31292\\2481922711.py:12: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(device.type==\"cuda\")):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[03/30] loss=0.9068  val_acc=0.6454  val_f1=0.6090  time=42.5s\n",
      "  ↳ Best improved. Saved to weights/fer_mobilenetv3_small_best.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hamseungjun\\AppData\\Local\\Temp\\ipykernel_31292\\2481922711.py:36: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(device.type==\"cuda\")):\n",
      "C:\\Users\\hamseungjun\\AppData\\Local\\Temp\\ipykernel_31292\\2481922711.py:12: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(device.type==\"cuda\")):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[04/30] loss=0.8507  val_acc=0.6385  val_f1=0.5966  time=47.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hamseungjun\\AppData\\Local\\Temp\\ipykernel_31292\\2481922711.py:36: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(device.type==\"cuda\")):\n",
      "C:\\Users\\hamseungjun\\AppData\\Local\\Temp\\ipykernel_31292\\2481922711.py:12: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(device.type==\"cuda\")):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05/30] loss=0.7875  val_acc=0.6437  val_f1=0.5977  time=41.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hamseungjun\\AppData\\Local\\Temp\\ipykernel_31292\\2481922711.py:36: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(device.type==\"cuda\")):\n",
      "C:\\Users\\hamseungjun\\AppData\\Local\\Temp\\ipykernel_31292\\2481922711.py:12: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(device.type==\"cuda\")):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[06/30] loss=0.7344  val_acc=0.6242  val_f1=0.5658  time=39.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hamseungjun\\AppData\\Local\\Temp\\ipykernel_31292\\2481922711.py:36: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(device.type==\"cuda\")):\n",
      "C:\\Users\\hamseungjun\\AppData\\Local\\Temp\\ipykernel_31292\\2481922711.py:12: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(device.type==\"cuda\")):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[07/30] loss=0.6851  val_acc=0.6461  val_f1=0.6040  time=37.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hamseungjun\\AppData\\Local\\Temp\\ipykernel_31292\\2481922711.py:36: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(device.type==\"cuda\")):\n",
      "C:\\Users\\hamseungjun\\AppData\\Local\\Temp\\ipykernel_31292\\2481922711.py:12: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(device.type==\"cuda\")):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[08/30] loss=0.6275  val_acc=0.6520  val_f1=0.6170  time=37.2s\n",
      "  ↳ Best improved. Saved to weights/fer_mobilenetv3_small_best.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hamseungjun\\AppData\\Local\\Temp\\ipykernel_31292\\2481922711.py:36: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(device.type==\"cuda\")):\n",
      "C:\\Users\\hamseungjun\\AppData\\Local\\Temp\\ipykernel_31292\\2481922711.py:12: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(device.type==\"cuda\")):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09/30] loss=0.5662  val_acc=0.6527  val_f1=0.5999  time=35.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hamseungjun\\AppData\\Local\\Temp\\ipykernel_31292\\2481922711.py:36: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(device.type==\"cuda\")):\n",
      "C:\\Users\\hamseungjun\\AppData\\Local\\Temp\\ipykernel_31292\\2481922711.py:12: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(device.type==\"cuda\")):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10/30] loss=0.5090  val_acc=0.6552  val_f1=0.6257  time=33.7s\n",
      "  ↳ Best improved. Saved to weights/fer_mobilenetv3_small_best.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hamseungjun\\AppData\\Local\\Temp\\ipykernel_31292\\2481922711.py:36: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(device.type==\"cuda\")):\n",
      "C:\\Users\\hamseungjun\\AppData\\Local\\Temp\\ipykernel_31292\\2481922711.py:12: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(device.type==\"cuda\")):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11/30] loss=0.4547  val_acc=0.6618  val_f1=0.6318  time=32.8s\n",
      "  ↳ Best improved. Saved to weights/fer_mobilenetv3_small_best.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hamseungjun\\AppData\\Local\\Temp\\ipykernel_31292\\2481922711.py:36: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(device.type==\"cuda\")):\n",
      "C:\\Users\\hamseungjun\\AppData\\Local\\Temp\\ipykernel_31292\\2481922711.py:12: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(device.type==\"cuda\")):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12/30] loss=0.3990  val_acc=0.6614  val_f1=0.6359  time=33.4s\n",
      "  ↳ Best improved. Saved to weights/fer_mobilenetv3_small_best.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hamseungjun\\AppData\\Local\\Temp\\ipykernel_31292\\2481922711.py:36: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(device.type==\"cuda\")):\n",
      "C:\\Users\\hamseungjun\\AppData\\Local\\Temp\\ipykernel_31292\\2481922711.py:12: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(device.type==\"cuda\")):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13/30] loss=0.3391  val_acc=0.6628  val_f1=0.6322  time=32.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hamseungjun\\AppData\\Local\\Temp\\ipykernel_31292\\2481922711.py:36: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(device.type==\"cuda\")):\n",
      "C:\\Users\\hamseungjun\\AppData\\Local\\Temp\\ipykernel_31292\\2481922711.py:12: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(device.type==\"cuda\")):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14/30] loss=0.2978  val_acc=0.6750  val_f1=0.6374  time=32.8s\n",
      "  ↳ Best improved. Saved to weights/fer_mobilenetv3_small_best.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hamseungjun\\AppData\\Local\\Temp\\ipykernel_31292\\2481922711.py:36: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(device.type==\"cuda\")):\n",
      "C:\\Users\\hamseungjun\\AppData\\Local\\Temp\\ipykernel_31292\\2481922711.py:12: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(device.type==\"cuda\")):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15/30] loss=0.2543  val_acc=0.6559  val_f1=0.6208  time=32.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hamseungjun\\AppData\\Local\\Temp\\ipykernel_31292\\2481922711.py:36: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(device.type==\"cuda\")):\n",
      "C:\\Users\\hamseungjun\\AppData\\Local\\Temp\\ipykernel_31292\\2481922711.py:12: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(device.type==\"cuda\")):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16/30] loss=0.2249  val_acc=0.6566  val_f1=0.6201  time=34.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hamseungjun\\AppData\\Local\\Temp\\ipykernel_31292\\2481922711.py:36: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(device.type==\"cuda\")):\n",
      "C:\\Users\\hamseungjun\\AppData\\Local\\Temp\\ipykernel_31292\\2481922711.py:12: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(device.type==\"cuda\")):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17/30] loss=0.1896  val_acc=0.6698  val_f1=0.6401  time=34.0s\n",
      "  ↳ Best improved. Saved to weights/fer_mobilenetv3_small_best.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hamseungjun\\AppData\\Local\\Temp\\ipykernel_31292\\2481922711.py:36: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(device.type==\"cuda\")):\n",
      "C:\\Users\\hamseungjun\\AppData\\Local\\Temp\\ipykernel_31292\\2481922711.py:12: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(device.type==\"cuda\")):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18/30] loss=0.1532  val_acc=0.6614  val_f1=0.6462  time=39.2s\n",
      "  ↳ Best improved. Saved to weights/fer_mobilenetv3_small_best.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hamseungjun\\AppData\\Local\\Temp\\ipykernel_31292\\2481922711.py:36: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(device.type==\"cuda\")):\n",
      "C:\\Users\\hamseungjun\\AppData\\Local\\Temp\\ipykernel_31292\\2481922711.py:12: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(device.type==\"cuda\")):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19/30] loss=0.1319  val_acc=0.6684  val_f1=0.6428  time=36.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hamseungjun\\AppData\\Local\\Temp\\ipykernel_31292\\2481922711.py:36: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(device.type==\"cuda\")):\n",
      "C:\\Users\\hamseungjun\\AppData\\Local\\Temp\\ipykernel_31292\\2481922711.py:12: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(device.type==\"cuda\")):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20/30] loss=0.1157  val_acc=0.6750  val_f1=0.6424  time=34.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hamseungjun\\AppData\\Local\\Temp\\ipykernel_31292\\2481922711.py:36: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(device.type==\"cuda\")):\n",
      "C:\\Users\\hamseungjun\\AppData\\Local\\Temp\\ipykernel_31292\\2481922711.py:12: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(device.type==\"cuda\")):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21/30] loss=0.0980  val_acc=0.6803  val_f1=0.6534  time=36.5s\n",
      "  ↳ Best improved. Saved to weights/fer_mobilenetv3_small_best.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hamseungjun\\AppData\\Local\\Temp\\ipykernel_31292\\2481922711.py:36: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(device.type==\"cuda\")):\n",
      "C:\\Users\\hamseungjun\\AppData\\Local\\Temp\\ipykernel_31292\\2481922711.py:12: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(device.type==\"cuda\")):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22/30] loss=0.0832  val_acc=0.6890  val_f1=0.6665  time=39.9s\n",
      "  ↳ Best improved. Saved to weights/fer_mobilenetv3_small_best.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hamseungjun\\AppData\\Local\\Temp\\ipykernel_31292\\2481922711.py:36: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(device.type==\"cuda\")):\n",
      "C:\\Users\\hamseungjun\\AppData\\Local\\Temp\\ipykernel_31292\\2481922711.py:12: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(device.type==\"cuda\")):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23/30] loss=0.0736  val_acc=0.6855  val_f1=0.6600  time=39.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hamseungjun\\AppData\\Local\\Temp\\ipykernel_31292\\2481922711.py:36: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(device.type==\"cuda\")):\n",
      "C:\\Users\\hamseungjun\\AppData\\Local\\Temp\\ipykernel_31292\\2481922711.py:12: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(device.type==\"cuda\")):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[24/30] loss=0.0651  val_acc=0.6893  val_f1=0.6605  time=38.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hamseungjun\\AppData\\Local\\Temp\\ipykernel_31292\\2481922711.py:36: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(device.type==\"cuda\")):\n",
      "C:\\Users\\hamseungjun\\AppData\\Local\\Temp\\ipykernel_31292\\2481922711.py:12: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(device.type==\"cuda\")):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[25/30] loss=0.0591  val_acc=0.6921  val_f1=0.6628  time=38.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hamseungjun\\AppData\\Local\\Temp\\ipykernel_31292\\2481922711.py:36: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(device.type==\"cuda\")):\n",
      "C:\\Users\\hamseungjun\\AppData\\Local\\Temp\\ipykernel_31292\\2481922711.py:12: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(device.type==\"cuda\")):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[26/30] loss=0.0542  val_acc=0.6942  val_f1=0.6642  time=38.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hamseungjun\\AppData\\Local\\Temp\\ipykernel_31292\\2481922711.py:36: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(device.type==\"cuda\")):\n",
      "C:\\Users\\hamseungjun\\AppData\\Local\\Temp\\ipykernel_31292\\2481922711.py:12: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(device.type==\"cuda\")):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[27/30] loss=0.0477  val_acc=0.6931  val_f1=0.6630  time=38.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hamseungjun\\AppData\\Local\\Temp\\ipykernel_31292\\2481922711.py:36: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(device.type==\"cuda\")):\n",
      "C:\\Users\\hamseungjun\\AppData\\Local\\Temp\\ipykernel_31292\\2481922711.py:12: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(device.type==\"cuda\")):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[28/30] loss=0.0440  val_acc=0.6890  val_f1=0.6583  time=38.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hamseungjun\\AppData\\Local\\Temp\\ipykernel_31292\\2481922711.py:36: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(device.type==\"cuda\")):\n",
      "C:\\Users\\hamseungjun\\AppData\\Local\\Temp\\ipykernel_31292\\2481922711.py:12: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(device.type==\"cuda\")):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[29/30] loss=0.0431  val_acc=0.6907  val_f1=0.6622  time=39.2s\n",
      "Early stopping triggered.\n",
      "Best val_f1: 0.6664689422319084\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "def evaluate(model, loader, device):\n",
    "    model.eval()\n",
    "    ys, yhs = [], []\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x = x.to(device, non_blocking=True)\n",
    "            y = y.to(device, non_blocking=True)\n",
    "            with torch.cuda.amp.autocast(enabled=(device.type==\"cuda\")):\n",
    "                logits = model(x)\n",
    "            yh = logits.argmax(1)\n",
    "            ys.append(y.detach().cpu().numpy())\n",
    "            yhs.append(yh.detach().cpu().numpy())\n",
    "    ys  = np.concatenate(ys)\n",
    "    yhs = np.concatenate(yhs)\n",
    "    acc = accuracy_score(ys, yhs)\n",
    "    f1  = f1_score(ys, yhs, average=\"macro\")\n",
    "    return acc, f1\n",
    "\n",
    "best_f1 = -1.0\n",
    "patience = 7\n",
    "pat = 0\n",
    "best_path = \"weights/fer_mobilenetv3_small_best.pth\"\n",
    "\n",
    "for ep in range(1, epochs+1):\n",
    "    model.train()\n",
    "    t0 = time.time()\n",
    "    losses = []\n",
    "    for x, y in train_loader:\n",
    "        x = x.to(device, non_blocking=True)\n",
    "        y = y.to(device, non_blocking=True)\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        with torch.cuda.amp.autocast(enabled=(device.type==\"cuda\")):\n",
    "            logits = model(x)\n",
    "            loss = criterion(logits, y)\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        losses.append(loss.item())\n",
    "    scheduler.step()\n",
    "    \n",
    "    val_acc, val_f1 = evaluate(model, val_loader, device)\n",
    "    tr_loss = float(np.mean(losses))\n",
    "    dt = time.time() - t0\n",
    "    print(f\"[{ep:02d}/{epochs}] loss={tr_loss:.4f}  val_acc={val_acc:.4f}  val_f1={val_f1:.4f}  time={dt:.1f}s\")\n",
    "    \n",
    "    if val_f1 > best_f1:\n",
    "        best_f1 = val_f1\n",
    "        pat = 0\n",
    "        torch.save({\"state_dict\": model.state_dict(),\n",
    "                    \"class_to_idx\": class_to_idx,\n",
    "                    \"epoch\": ep}, best_path)\n",
    "        print(f\"  ↳ Best improved. Saved to {best_path}\")\n",
    "    else:\n",
    "        pat += 1\n",
    "        if pat >= patience:\n",
    "            print(\"Early stopping triggered.\")\n",
    "            break\n",
    "\n",
    "print(\"Best val_f1:\", best_f1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "434216bf",
   "metadata": {},
   "source": [
    "\n",
    "## 6. 테스트(선택)\n",
    "- Kaggle FER2013에는 `test` 폴더가 있습니다. 존재하면 테스트 점수도 확인합니다.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e52510f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hamseungjun\\AppData\\Local\\Temp\\ipykernel_31292\\2481922711.py:12: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(device.type==\"cuda\")):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TEST] acc=0.6828, macro-f1=0.6716\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if test_loader is not None:\n",
    "    ckpt = torch.load(\"weights/fer_mobilenetv3_small_best.pth\", map_location=device)\n",
    "    model.load_state_dict(ckpt[\"state_dict\"])\n",
    "    test_acc, test_f1 = evaluate(model, test_loader, device)\n",
    "    print(f\"[TEST] acc={test_acc:.4f}, macro-f1={test_f1:.4f}\")\n",
    "else:\n",
    "    print(\"No test set detected — skipped.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ed1098",
   "metadata": {},
   "source": [
    "\n",
    "## 7. (선택) TorchScript 내보내기\n",
    "- 실시간 추론 배포를 위한 TorchScript 파일도 저장합니다.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b27afd8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved TorchScript: weights/fer_mobilenetv3_small_best.ts\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# TorchScript export (optional)\n",
    "script_path = \"weights/fer_mobilenetv3_small_best.ts\"\n",
    "ckpt = torch.load(\"weights/fer_mobilenetv3_small_best.pth\", map_location=device)\n",
    "model.load_state_dict(ckpt[\"state_dict\"])\n",
    "model.eval()\n",
    "\n",
    "example = torch.randn(1, 3, 224, 224, device=device)\n",
    "traced = torch.jit.trace(model, example)\n",
    "traced.save(script_path)\n",
    "print(\"Saved TorchScript:\", script_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f26593d3",
   "metadata": {},
   "source": [
    "\n",
    "## 8. 다음 단계 (피로도 스코어링 결합)\n",
    "- 위 모델의 **감정 확률**을 이용해, 다음과 같이 피로도 스코어를 만들 수 있습니다.\n",
    "  - `p_neg = p(sad)+p(disgust)+p(angry)+α·p(neutral)`\n",
    "  - Valence/Arousal 회귀 모델(추가 학습) 또는 AU(눈감김/하품) 피쳐와 합성\n",
    "- 별도 요청 시: **EAR/MAR 계산 + 실시간 FatigueScore** 추론 노트북/웹 데모 제공 가능\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1dca90ab-a27f-44eb-8c54-048c45b78d53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "idx_to_class: {0: 'angry', 1: 'disgust', 2: 'fear', 3: 'happy', 4: 'neutral', 5: 'sad', 6: 'surprise'}\n",
      "{\n",
      "  \"angry\": 1.71044989283331e-09,\n",
      "  \"disgust\": 8.918034088978288e-10,\n",
      "  \"fear\": 0.004994899500161409,\n",
      "  \"happy\": 1.2655708303555002e-07,\n",
      "  \"neutral\": 0.00042139278957620263,\n",
      "  \"sad\": 0.994579553604126,\n",
      "  \"surprise\": 4.049762992508477e-06\n",
      "}\n",
      "raw=0.995, fatigue=9.9\n",
      "[With AU] raw=0.737 fatigue=7.4\n"
     ]
    }
   ],
   "source": [
    "# === 감정 확률 → 피로도 스코어 산출 ===\n",
    "# 전제: weights/fer_mobilenetv3_small_best.pth, weights/class_to_idx.json 존재\n",
    "import os, json, math, torch, numpy as np\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from torchvision.models import mobilenet_v3_small\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 1) 클래스 매핑 로드\n",
    "with open(\"weights/class_to_idx.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    class_to_idx = json.load(f)\n",
    "idx_to_class = {v: k for k, v in class_to_idx.items()}\n",
    "print(\"idx_to_class:\", idx_to_class)\n",
    "\n",
    "# FER2013 일반 클래스(예시): angry, disgust, fear, happy, neutral, sad, surprise\n",
    "NEG_LABELS = [\"sad\", \"disgust\", \"angry\"]   # 피로에 기여하는 부정 감정 집합\n",
    "NEUTRAL_LABEL = \"neutral\"\n",
    "ALPHA_NEUTRAL = 0.5                        # 중립 가중치 α\n",
    "\n",
    "# 2) 모델 로드 (학습한 가중치 불러오기)\n",
    "num_classes = len(class_to_idx)\n",
    "model = mobilenet_v3_small(weights=None)\n",
    "# classifier[3]가 최종 Linear(개수는 torchvision 버전에 따라 달라질 수 있음)\n",
    "# 아래는 최신 기준(MobileNetV3-Small의 마지막 Linear가 classifier[3])에 맞춤\n",
    "in_features = model.classifier[3].in_features\n",
    "model.classifier[3] = torch.nn.Linear(in_features, num_classes)\n",
    "ckpt = torch.load(\"weights/fer_mobilenetv3_small_best.pth\", map_location=device)\n",
    "model.load_state_dict(ckpt[\"state_dict\"])\n",
    "model.eval().to(device)\n",
    "\n",
    "# 3) 전처리(검증과 동일)\n",
    "IMG_SIZE = 224\n",
    "inference_tfms = transforms.Compose([\n",
    "    transforms.Resize(IMG_SIZE + 32),\n",
    "    transforms.CenterCrop(IMG_SIZE),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "@torch.no_grad()\n",
    "def predict_emotion_probs(img: Image.Image, temperature: float = 1.0):\n",
    "    \"\"\"\n",
    "    입력: PIL Image\n",
    "    출력: 감정 확률 dict 예) {\"angry\":0.01, \"happy\":0.72, ...}\n",
    "    \"\"\"\n",
    "    x = inference_tfms(img).unsqueeze(0).to(device)\n",
    "    logits = model(x)\n",
    "    if temperature is not None and temperature > 0:\n",
    "        logits = logits / float(temperature)\n",
    "    probs = F.softmax(logits, dim=1).squeeze(0).detach().cpu().numpy()\n",
    "    probs_dict = {idx_to_class[i]: float(probs[i]) for i in range(len(probs))}\n",
    "    return probs_dict\n",
    "\n",
    "# 4) 피로도 스코어러 (감정 확률 기반 + 선택적 AU 훅)\n",
    "class FatigueScorer:\n",
    "    \"\"\"\n",
    "    감정 확률 기반 피로도 스코어러\n",
    "    - 기본: p_neg = p(sad)+p(disgust)+p(angry) + α·p(neutral)\n",
    "    - 선택: eye_close, yawn(0~1)을 받아 AU 결합 가능\n",
    "    - EWMA(β)로 시간 평활\n",
    "    최종 FatigueScore ∈ [0, 100]\n",
    "    \"\"\"\n",
    "    def __init__(self, w_neg=1.0, w_au_eye=0.0, w_au_yawn=0.0, beta=0.9):\n",
    "        self.w_neg = float(w_neg)\n",
    "        self.w_au_eye = float(w_au_eye)\n",
    "        self.w_au_yawn = float(w_au_yawn)\n",
    "        self.beta = float(beta)\n",
    "        self.state = 0.0  # EWMA 내부 상태\n",
    "\n",
    "    def _p_neg(self, probs_dict):\n",
    "        s = 0.0\n",
    "        for lab in NEG_LABELS:\n",
    "            if lab in probs_dict:\n",
    "                s += probs_dict[lab]\n",
    "        if NEUTRAL_LABEL in probs_dict:\n",
    "            s += ALPHA_NEUTRAL * probs_dict[NEUTRAL_LABEL]\n",
    "        return float(np.clip(s, 0.0, 1.0))\n",
    "\n",
    "    def score_frame(self, probs_dict, eye_close=0.0, yawn=0.0):\n",
    "        # 감정 기반 원시 점수\n",
    "        s = self.w_neg * self._p_neg(probs_dict)\n",
    "        # AU(선택)\n",
    "        s += self.w_au_eye * float(np.clip(eye_close, 0.0, 1.0))\n",
    "        s += self.w_au_yawn * float(np.clip(yawn, 0.0, 1.0))\n",
    "        s = float(np.clip(s, 0.0, 1.0))\n",
    "        # EWMA 평활\n",
    "        self.state = self.beta * self.state + (1.0 - self.beta) * s\n",
    "        fatigue = 100.0 * float(np.clip(self.state, 0.0, 1.0))\n",
    "        return fatigue, s  # (평활 점수, 원시 점수)\n",
    "\n",
    "    def reset(self):\n",
    "        self.state = 0.0\n",
    "\n",
    "# 기본: 감정만 사용 (w_neg=1.0)\n",
    "scorer = FatigueScorer(w_neg=1.0, w_au_eye=0.0, w_au_yawn=0.0, beta=0.9)\n",
    "\n",
    "def fatigue_from_image_path(img_path, temperature=1.0, eye_close=0.0, yawn=0.0):\n",
    "    \"\"\"\n",
    "    경로 이미지 한 장에서 피로도 스코어 계산\n",
    "    반환: (probs_dict, raw_score_0to1, fatigue_0to100)\n",
    "    \"\"\"\n",
    "    img = Image.open(img_path).convert(\"RGB\")\n",
    "    probs = predict_emotion_probs(img, temperature=temperature)\n",
    "    fatigue, raw = scorer.score_frame(probs, eye_close=eye_close, yawn=yawn)\n",
    "    return probs, raw, fatigue\n",
    "\n",
    "# === 사용 예시 ===\n",
    "# 1) 단일 이미지\n",
    "demo_img = \"demo.jpg\"  # 테스트할 이미지 경로\n",
    "if os.path.exists(demo_img):\n",
    "    probs, raw, fatigue = fatigue_from_image_path(demo_img, temperature=1.0)\n",
    "    print(json.dumps(probs, ensure_ascii=False, indent=2))\n",
    "    print(f\"raw={raw:.3f}, fatigue={fatigue:.1f}\")\n",
    "else:\n",
    "    print(\"demo.jpg가 없습니다. 경로를 바꿔 실행하세요.\")\n",
    "\n",
    "# 2) 폴더 일괄 처리\n",
    "from glob import glob\n",
    "def batch_fatigue_on_folder(folder=\"demo_images\"):\n",
    "    exts = (\"*.jpg\", \"*.jpeg\", \"*.png\", \"*.bmp\", \"*.webp\")\n",
    "    paths = []\n",
    "    for e in exts:\n",
    "        paths += glob(os.path.join(folder, e))\n",
    "    if not paths:\n",
    "        print(\"폴더에 이미지가 없습니다:\", folder)\n",
    "        return\n",
    "    scorer.reset()\n",
    "    rows = []\n",
    "    for p in sorted(paths):\n",
    "        probs, raw, fatigue = fatigue_from_image_path(p)\n",
    "        rows.append((p, raw, fatigue))\n",
    "        print(f\"{os.path.basename(p):30s} raw={raw:.3f} fatigue={fatigue:.1f}\")\n",
    "    fats = [f for _, _, f in rows]\n",
    "    print(f\"Summary: n={len(rows)}  mean={np.mean(fats):.1f}  max={np.max(fats):.1f}\")\n",
    "    return rows\n",
    "\n",
    "# 3) AU(눈감김/하품) 결합 예시 (가상 값)\n",
    "scorer = FatigueScorer(w_neg=0.6, w_au_eye=0.3, w_au_yawn=0.1, beta=0.9)\n",
    "if os.path.exists(\"demo.jpg\"):\n",
    "    fake_eye_close = 0.4  # 최근 10초 눈감김 비율(예)\n",
    "    fake_yawn = 0.2       # 하품 강도/빈도(예)\n",
    "    probs = predict_emotion_probs(Image.open(\"demo.jpg\").convert(\"RGB\"))\n",
    "    fatigue, raw = scorer.score_frame(probs, eye_close=fake_eye_close, yawn=fake_yawn)\n",
    "    print(f\"[With AU] raw={raw:.3f} fatigue={fatigue:.1f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6caf1c25-2d8b-4658-abb1-187ff8b5d871",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
